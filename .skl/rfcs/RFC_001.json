{
  "id": "RFC_001",
  "status": "open",
  "created_at": "2026-02-28T00:00:00.000Z",
  "triggering_proposal": "p-arch-001",
  "decision_required": "Which caching strategy should the auth service use?",
  "context": "The auth service currently has no caching layer. Token validation hits the database on every request, causing P95 latency > 200ms under load. Two viable approaches have been identified.",
  "option_a": {
    "description": "In-process LRU cache with a 60-second TTL, keyed by token hash.",
    "consequences": "Fast (< 1ms lookup), no external dependency. Stale tokens can remain valid for up to 60 seconds after revocation."
  },
  "option_b": {
    "description": "Redis-backed distributed cache, TTL matches token expiry.",
    "consequences": "Tokens invalidated immediately on revocation. Adds Redis as a required infrastructure dependency and increases operational complexity."
  },
  "option_c": {
    "description": "No caching â€” add a read replica database and direct all validation reads there.",
    "consequences": "Zero staleness risk. Requires provisioning a read replica. Latency still higher than an in-process cache under burst load."
  },
  "orchestrator_recommendation": "option_a",
  "orchestrator_rationale": "In-process LRU satisfies the P95 target without adding infrastructure. The 60-second revocation window is acceptable given the token lifetime is 24 hours."
}
